{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10 #defined from datasets\n",
    "epochs = 10\n",
    "validation_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### permute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permuate_data(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = np.random.permutation(x[i])\n",
    "        for j in range(len(x[i])):\n",
    "            x[i][j] = np.random.permutation(x[i][j])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(dataset):\n",
    "  (X_train, y_train), (X_test, y_test) = dataset.load_data()\n",
    "\n",
    "  X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "  X_train = X_train.reshape(int(60000 * (1.0 - validation_size)), 28, 28, 1)\n",
    "  X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "  X_valid = X_valid.reshape(int(60000 * validation_size), 28, 28, 1)\n",
    "\n",
    "  X_train = X_train.astype('float32')\n",
    "  X_test = X_test.astype('float32')\n",
    "  X_valid = X_valid.astype('float32')\n",
    "\n",
    "  X_train /= 255\n",
    "  X_test /= 255\n",
    "  X_valid /= 255\n",
    "\n",
    "  # convert class vectors to binary class matrices\n",
    "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "  y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "\n",
    "  X_train = permuate_data(X_train)\n",
    "  X_test = permuate_data(X_test)\n",
    "  X_valid = permuate_data(X_valid)\n",
    "\n",
    "  return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, X_train, y_train, X_valid, y_valid, optim='sgd'):\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"])\n",
    "    \n",
    "    #track epoch loss history\n",
    "    history = model.fit(X_train, y_train, epochs=epochs,\n",
    "                        validation_data=(X_valid, y_valid))\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltHistory(history):\n",
    "  pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "  plt.grid(True)\n",
    "  plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "  plt.title(\"Loss and Accuracy over Epochs\")\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.yablel('Loss/Accuracy')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute experiments for a given model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExperiment(model, dataset, plot_hist=True):\n",
    "  X_train, y_train, X_test, y_test, X_valid, y_valid = splitData(dataset)\n",
    "  # print(\"--- Training Model ...\")\n",
    "  history = trainModel(model, X_train, y_train, X_valid, y_valid)\n",
    "  if plot_hist == True:\n",
    "    print(\"\\n\\n ========= History =========\")\n",
    "    pltHistory(history)\n",
    "  print(\"\\n\\n ========= Evaluation (Loss, Accuracy) ========= \")\n",
    "  return model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = keras.models.Sequential([\n",
    "  keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "  keras.layers.Dense(300, activation=\"relu\"),\n",
    "  keras.layers.Dense(100, activation=\"relu\"),\n",
    "  keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doExperiment(mlp_model, mnist, plot_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fashion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doExperiment(mlp_model, fashion_mnist, plot_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "cnn_model = keras.models.Sequential([\n",
    "DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "keras.layers.MaxPooling2D(pool_size=2),\n",
    "DefaultConv2D(filters=128),\n",
    "DefaultConv2D(filters=128),\n",
    "keras.layers.MaxPooling2D(pool_size=2),\n",
    "DefaultConv2D(filters=256),\n",
    "DefaultConv2D(filters=256),\n",
    "keras.layers.MaxPooling2D(pool_size=2),\n",
    "keras.layers.Flatten(),\n",
    "keras.layers.Dense(units=128, activation='relu'),\n",
    "keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(units=64, activation='relu'),\n",
    "keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doExperiment(cnn_model, mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fashion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doExperiment(cnn_model, fashion_mnist)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

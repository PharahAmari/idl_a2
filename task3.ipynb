{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "#load the data and split it into train and test sets\n",
    "x = np.load('data/images.npy')\n",
    "y = np.load('data/labels.npy')\n",
    "\n",
    "#scale pixel density to 0-1 by dividing by 255\n",
    "x = x.astype(float)\n",
    "x /= 255.0\n",
    "\n",
    "img_rows = len(x[0])\n",
    "img_cols = len(x[0][0])\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x = x.reshape(x.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x = x.reshape(x.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)\n",
    "\n",
    "print(x[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.0815e-07 - mean_squared_error: 46.7903 - accuracy: 0.0013\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1289e-07 - mean_squared_error: 47.3079 - accuracy: 0.0013\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1017e-07 - mean_squared_error: 47.1038 - accuracy: 0.0013\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1453e-07 - mean_squared_error: 47.4418 - accuracy: 0.0010\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1747e-07 - mean_squared_error: 47.7499 - accuracy: 0.0011\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1359e-07 - mean_squared_error: 47.4800 - accuracy: 0.0018\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1589e-07 - mean_squared_error: 47.4883 - accuracy: 9.5653e-04\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1708e-07 - mean_squared_error: 47.8197 - accuracy: 0.0011\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 27s 59ms/step - loss: 7.1066e-07 - mean_squared_error: 47.1034 - accuracy: 0.0017\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 27s 59ms/step - loss: 7.1896e-07 - mean_squared_error: 47.9951 - accuracy: 7.4155e-04\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 26s 59ms/step - loss: 7.1144e-07 - mean_squared_error: 47.1025 - accuracy: 0.0011\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 27s 59ms/step - loss: 7.1503e-07 - mean_squared_error: 47.5351 - accuracy: 0.0017\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 27s 59ms/step - loss: 7.1261e-07 - mean_squared_error: 47.2981 - accuracy: 0.0016\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1559e-07 - mean_squared_error: 47.5433 - accuracy: 0.0014\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1620e-07 - mean_squared_error: 47.7719 - accuracy: 0.0017\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.2106e-07 - mean_squared_error: 48.0983 - accuracy: 0.0017\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1702e-07 - mean_squared_error: 47.8950 - accuracy: 9.1127e-04\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1293e-07 - mean_squared_error: 47.3459 - accuracy: 0.0011\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.2571e-07 - mean_squared_error: 48.6146 - accuracy: 0.0015\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.0884e-07 - mean_squared_error: 46.9424 - accuracy: 0.0018\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1708e-07 - mean_squared_error: 47.9266 - accuracy: 9.4155e-04\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1532e-07 - mean_squared_error: 47.5020 - accuracy: 0.0013\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1315e-07 - mean_squared_error: 47.1647 - accuracy: 0.0013\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1139e-07 - mean_squared_error: 47.0661 - accuracy: 9.0021e-04\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.2090e-07 - mean_squared_error: 48.0867 - accuracy: 0.0011\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1355e-07 - mean_squared_error: 47.5274 - accuracy: 0.0013\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1116e-07 - mean_squared_error: 47.1227 - accuracy: 0.0014\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1556e-07 - mean_squared_error: 47.7028 - accuracy: 0.0017\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1875e-07 - mean_squared_error: 47.8491 - accuracy: 0.0013\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1463e-07 - mean_squared_error: 47.4930 - accuracy: 0.0014\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 7.0957e-07 - mean_squared_error: 46.8420 - accuracy: 0.0017\n",
      "common sense error on average: 181.6561111111111\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 done\n",
      "-------------------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1286e-07 - mean_squared_error: 47.8201 - accuracy: 0.0016\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1153e-07 - mean_squared_error: 47.6037 - accuracy: 0.0014\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.2074e-07 - mean_squared_error: 48.5929 - accuracy: 0.0011\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1235e-07 - mean_squared_error: 47.8399 - accuracy: 0.0011\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1983e-07 - mean_squared_error: 48.6251 - accuracy: 0.0013\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1181e-07 - mean_squared_error: 47.9554 - accuracy: 0.0014\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1160e-07 - mean_squared_error: 47.7144 - accuracy: 0.0015\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1150e-07 - mean_squared_error: 47.8517 - accuracy: 0.0011\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1885e-07 - mean_squared_error: 48.3875 - accuracy: 0.0014\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1328e-07 - mean_squared_error: 47.8482 - accuracy: 0.0012\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1596e-07 - mean_squared_error: 48.2317 - accuracy: 0.0015\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1829e-07 - mean_squared_error: 48.5009 - accuracy: 0.0011\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1865e-07 - mean_squared_error: 48.4708 - accuracy: 0.0014\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1390e-07 - mean_squared_error: 47.9643 - accuracy: 0.0013\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1660e-07 - mean_squared_error: 48.1025 - accuracy: 9.5010e-04\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1495e-07 - mean_squared_error: 48.1558 - accuracy: 0.0012\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1336e-07 - mean_squared_error: 48.0318 - accuracy: 9.3737e-04\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1630e-07 - mean_squared_error: 48.1910 - accuracy: 9.4659e-04\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1663e-07 - mean_squared_error: 48.2494 - accuracy: 0.0017\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1167e-07 - mean_squared_error: 47.7422 - accuracy: 0.0012\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1361e-07 - mean_squared_error: 47.9589 - accuracy: 0.0015\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.2109e-07 - mean_squared_error: 48.8562 - accuracy: 0.0019\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 26s 59ms/step - loss: 7.1441e-07 - mean_squared_error: 48.0360 - accuracy: 0.0017\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1495e-07 - mean_squared_error: 48.0035 - accuracy: 0.0013\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1726e-07 - mean_squared_error: 48.4444 - accuracy: 0.0018\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1695e-07 - mean_squared_error: 48.2252 - accuracy: 0.0012\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1321e-07 - mean_squared_error: 47.9786 - accuracy: 0.0013\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1806e-07 - mean_squared_error: 48.3320 - accuracy: 0.0011\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1770e-07 - mean_squared_error: 48.4593 - accuracy: 0.0020\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1510e-07 - mean_squared_error: 48.0910 - accuracy: 0.0015\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 7.0957e-07 - mean_squared_error: 47.1813 - accuracy: 0.0017\n",
      "common sense error on average: 181.66555555555556\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 2 done\n",
      "-------------------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.0963e-07 - mean_squared_error: 47.4996 - accuracy: 0.0012\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1395e-07 - mean_squared_error: 47.9874 - accuracy: 9.4308e-04\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1901e-07 - mean_squared_error: 48.4288 - accuracy: 0.0014\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1164e-07 - mean_squared_error: 47.6539 - accuracy: 0.0013\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1691e-07 - mean_squared_error: 48.0119 - accuracy: 0.0012\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1412e-07 - mean_squared_error: 48.0165 - accuracy: 9.9978e-04\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1987e-07 - mean_squared_error: 48.5455 - accuracy: 0.0021\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1503e-07 - mean_squared_error: 47.9999 - accuracy: 0.0011\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1440e-07 - mean_squared_error: 48.0538 - accuracy: 0.0012\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1285e-07 - mean_squared_error: 47.8627 - accuracy: 0.0011\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1359e-07 - mean_squared_error: 47.8705 - accuracy: 0.0017\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1534e-07 - mean_squared_error: 47.9803 - accuracy: 8.2312e-04\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1435e-07 - mean_squared_error: 48.0057 - accuracy: 0.0011\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1434e-07 - mean_squared_error: 48.0066 - accuracy: 9.5942e-04\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1726e-07 - mean_squared_error: 48.2240 - accuracy: 0.0011\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1867e-07 - mean_squared_error: 48.3401 - accuracy: 0.0013\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1925e-07 - mean_squared_error: 48.4714 - accuracy: 8.7623e-04\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1596e-07 - mean_squared_error: 47.9922 - accuracy: 0.0018\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1922e-07 - mean_squared_error: 48.3195 - accuracy: 0.0010\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.0439e-07 - mean_squared_error: 46.9605 - accuracy: 0.0013\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1495e-07 - mean_squared_error: 48.0461 - accuracy: 0.0012\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1367e-07 - mean_squared_error: 47.9293 - accuracy: 0.0014\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1484e-07 - mean_squared_error: 48.0886 - accuracy: 0.0014\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1003e-07 - mean_squared_error: 47.5207 - accuracy: 0.0013\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1320e-07 - mean_squared_error: 47.9031 - accuracy: 0.0014\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1882e-07 - mean_squared_error: 48.4656 - accuracy: 9.9524e-04\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.2019e-07 - mean_squared_error: 48.6408 - accuracy: 0.0019\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1098e-07 - mean_squared_error: 47.6599 - accuracy: 0.0010\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1109e-07 - mean_squared_error: 47.5797 - accuracy: 9.5057e-04\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1420e-07 - mean_squared_error: 47.8556 - accuracy: 7.7366e-04\n",
      "113/113 [==============================] - 3s 24ms/step - loss: 7.0957e-07 - mean_squared_error: 47.1934 - accuracy: 0.0017\n",
      "common sense error on average: 181.67472222222221\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 3 done\n",
      "-------------------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 7.1743e-07 - mean_squared_error: 47.7975 - accuracy: 0.0014\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1935e-07 - mean_squared_error: 48.0795 - accuracy: 0.0014\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1543e-07 - mean_squared_error: 47.7147 - accuracy: 0.0011\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1910e-07 - mean_squared_error: 47.9759 - accuracy: 0.0013\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1724e-07 - mean_squared_error: 47.6966 - accuracy: 0.0011\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 7.1784e-07 - mean_squared_error: 47.8351 - accuracy: 0.0015\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 7.1784e-07 - mean_squared_error: 47.8593 - accuracy: 0.0018\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.2167e-07 - mean_squared_error: 48.2623 - accuracy: 0.0011\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 7.1653e-07 - mean_squared_error: 47.5793 - accuracy: 0.0010\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1968e-07 - mean_squared_error: 48.1448 - accuracy: 7.7355e-04\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1363e-07 - mean_squared_error: 47.4742 - accuracy: 0.0015\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 28s 61ms/step - loss: 7.1425e-07 - mean_squared_error: 47.4140 - accuracy: 0.0012\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1565e-07 - mean_squared_error: 47.6025 - accuracy: 0.0015\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1489e-07 - mean_squared_error: 47.5054 - accuracy: 0.0011\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.0810e-07 - mean_squared_error: 46.9298 - accuracy: 0.0011\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1339e-07 - mean_squared_error: 47.4442 - accuracy: 0.0018\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1831e-07 - mean_squared_error: 47.7861 - accuracy: 0.0017\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1427e-07 - mean_squared_error: 47.3204 - accuracy: 0.0010\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.2133e-07 - mean_squared_error: 48.1021 - accuracy: 0.0013\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1738e-07 - mean_squared_error: 47.5974 - accuracy: 0.0014\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1121e-07 - mean_squared_error: 47.1622 - accuracy: 0.0015\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1569e-07 - mean_squared_error: 47.6316 - accuracy: 0.0020\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1579e-07 - mean_squared_error: 47.7213 - accuracy: 9.8830e-04\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1786e-07 - mean_squared_error: 47.9433 - accuracy: 0.0015\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1421e-07 - mean_squared_error: 47.4300 - accuracy: 0.0016\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1487e-07 - mean_squared_error: 47.4138 - accuracy: 0.0014\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1402e-07 - mean_squared_error: 47.5500 - accuracy: 0.0016\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1485e-07 - mean_squared_error: 47.5719 - accuracy: 0.0010\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1270e-07 - mean_squared_error: 47.2584 - accuracy: 0.0016\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1150e-07 - mean_squared_error: 47.3164 - accuracy: 0.0013\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 7.0957e-07 - mean_squared_error: 46.8500 - accuracy: 0.0017\n",
      "common sense error on average: 181.6538888888889\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 4 done\n",
      "-------------------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1399e-07 - mean_squared_error: 47.8440 - accuracy: 0.0011\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1306e-07 - mean_squared_error: 47.7448 - accuracy: 8.4734e-04\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1980e-07 - mean_squared_error: 48.4580 - accuracy: 0.0012\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1877e-07 - mean_squared_error: 48.4807 - accuracy: 0.0013\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1671e-07 - mean_squared_error: 48.2007 - accuracy: 0.0022\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.2131e-07 - mean_squared_error: 48.6223 - accuracy: 0.0012\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1274e-07 - mean_squared_error: 47.6761 - accuracy: 0.0012\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1909e-07 - mean_squared_error: 48.3125 - accuracy: 0.0014\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1638e-07 - mean_squared_error: 48.0965 - accuracy: 0.0013\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1318e-07 - mean_squared_error: 47.8828 - accuracy: 0.0014\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1349e-07 - mean_squared_error: 47.8426 - accuracy: 0.0013\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 7.1463e-07 - mean_squared_error: 47.9894 - accuracy: 0.0011\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1539e-07 - mean_squared_error: 47.9069 - accuracy: 0.0015\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1799e-07 - mean_squared_error: 48.2633 - accuracy: 0.0012\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1289e-07 - mean_squared_error: 47.9084 - accuracy: 0.0020\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1690e-07 - mean_squared_error: 48.0750 - accuracy: 0.0014\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1455e-07 - mean_squared_error: 47.9440 - accuracy: 0.0018\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1846e-07 - mean_squared_error: 48.2427 - accuracy: 0.0014\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1674e-07 - mean_squared_error: 48.2347 - accuracy: 0.0014\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.2087e-07 - mean_squared_error: 48.5691 - accuracy: 9.9353e-04\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 27s 60ms/step - loss: 7.1193e-07 - mean_squared_error: 47.6284 - accuracy: 0.0018\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1534e-07 - mean_squared_error: 48.1187 - accuracy: 0.0011\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1197e-07 - mean_squared_error: 47.5557 - accuracy: 0.0012\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1229e-07 - mean_squared_error: 47.8213 - accuracy: 0.0014\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1676e-07 - mean_squared_error: 48.0859 - accuracy: 0.0015\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1698e-07 - mean_squared_error: 48.2731 - accuracy: 9.6775e-04\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1308e-07 - mean_squared_error: 47.7689 - accuracy: 0.0012\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.1419e-07 - mean_squared_error: 47.9819 - accuracy: 0.0012\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 7.1478e-07 - mean_squared_error: 48.0864 - accuracy: 0.0014\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 7.2047e-07 - mean_squared_error: 48.3892 - accuracy: 0.0017\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 7.0957e-07 - mean_squared_error: 47.2137 - accuracy: 0.0017\n",
      "common sense error on average: 181.67055555555555\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 5 done\n",
      "-------------------------\n",
      "average CSE: 181.66416666666666\n",
      "average loss: 7.095662795109092e-07\n",
      "average accurary: 0.0016666667070239782\n",
      "average MSE: 47.056077575683595\n"
     ]
    }
   ],
   "source": [
    "#Aprroach 1, regression\n",
    "\n",
    "y_reg_train = np.zeros(len(y_train))\n",
    "y_reg_test = np.zeros(len(y_test))\n",
    "for i in range(len(y_train)):\n",
    "    hour = y_train[i][0]\n",
    "    minutes = y_train[i][1] / 60 \n",
    "    y_reg_train[i] = hour + minutes\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    hour = y_test[i][0]\n",
    "    minutes = y_test[i][1] / 60 \n",
    "    y_reg_test[i] = hour + minutes\n",
    "\n",
    "#common sense error for the regression method\n",
    "#both times are in the form of float\n",
    "#return the amount of minutes of difference between times\n",
    "#max_difference is the maximal difference between two time labels, which is 6 hours, thus 6*60=360 minutes\n",
    "#max_time is the maximal time in numbers which is 12*60=720, needed to calculate the absolute difference from 12:00 (00:00)\n",
    "def cse_reg(time1, time2, max_difference=360, max_time=720):\n",
    "    #time in the form of minutes, rounded\n",
    "    time1 = round(time1 * 60)\n",
    "    time2 = round(time2 * 60 )\n",
    "    if time2 > time1: difference = time2 -time1\n",
    "    else: difference = time1 - time2\n",
    "\n",
    "    if difference > max_difference:\n",
    "        difference = max_time - difference\n",
    "    \n",
    "    return difference\n",
    "\n",
    "\n",
    "def calculate_cse(y_true, y_pred):\n",
    "    error_list = [ ]\n",
    "    for i in range(len(y_true)):\n",
    "        difference = cse_reg(y_true[i], y_pred[i][0])\n",
    "        error_list.append(difference)\n",
    "    return error_list, np.mean(error_list)\n",
    "\n",
    "\n",
    "#store the hsitories,\n",
    "# also store the accuracies, mse's and loss of the last epoch,= for each experiment \n",
    "# also the common sense error (CSE)\n",
    "histories = [ ]\n",
    "accuracies = [ ]\n",
    "mses = []\n",
    "losses = []\n",
    "cses = []\n",
    "\n",
    "experiments = 5\n",
    "\n",
    "for i in range(experiments):\n",
    "    #create the model\n",
    "    DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=input_shape),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    #DefaultConv2D(filters=512),\n",
    "    #DefaultConv2D(filters=512),\n",
    "    #keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer='sgd',\n",
    "        metrics=['mean_squared_error', 'accuracy'])\n",
    "\n",
    "    history = model.fit(x_train,y_reg_train, epochs=30)\n",
    "    \n",
    "\n",
    "    temp = model.evaluate(x_test,y_reg_test)\n",
    "    losses.append(temp[0])\n",
    "    mses.append(temp[1])\n",
    "    accuracies.append(temp[2])\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    error_list, common_sense_error = calculate_cse(y_reg_test, y_pred)\n",
    "    print(\"common sense error on average: \" + str(common_sense_error))\n",
    "    cses.append(common_sense_error)\n",
    "\n",
    "\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1) \n",
    "    plt.show()\n",
    "\n",
    "    print(\"Experiment \" + str(i+1) + \" done\")\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "\n",
    "print(\"average CSE: \" + str(np.mean(cses)))\n",
    "print(\"average loss: \" + str(np.mean(losses)))\n",
    "print(\"average accurary: \" + str(np.mean(accuracies)))\n",
    "print(\"average MSE: \" + str(np.mean(mses)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "450/450 [==============================] - 44s 62ms/step - loss: 3.1787 - accuracy: 0.0395\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1782 - accuracy: 0.0413\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1784 - accuracy: 0.0382\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1782 - accuracy: 0.0388\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0370\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1780 - accuracy: 0.0425\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0433\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0425\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0425\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0400\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0385\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0410\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0441\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0402\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1779 - accuracy: 0.0452\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0414\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0415\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0411\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0415\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0368\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0474\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0400\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0391\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1779 - accuracy: 0.0447\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0453\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0421\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0410\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 30s 66ms/step - loss: 3.1781 - accuracy: 0.0412\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0450\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1780 - accuracy: 0.0433\n",
      "113/113 [==============================] - 4s 33ms/step - loss: 3.1784 - accuracy: 0.0392\n",
      "accuracy for model: 0.03916666656732559\n",
      "experiment 1 done\n",
      "-----------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1792 - accuracy: 0.0433\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1785 - accuracy: 0.0383\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1783 - accuracy: 0.0384\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0427\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0411\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0418\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0446\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0405\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0439\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0422\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0366\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0435\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0408\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1780 - accuracy: 0.0386\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0387\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0420\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1780 - accuracy: 0.0454\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0411\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0430\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0436\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0433\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0426\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0429\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1784 - accuracy: 0.0431\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0463\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1780 - accuracy: 0.0394\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0410\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0442\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0432\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0406\n",
      "113/113 [==============================] - 3s 23ms/step - loss: 3.1784 - accuracy: 0.0392\n",
      "accuracy for model: 0.03916666656732559\n",
      "experiment 2 done\n",
      "-----------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1789 - accuracy: 0.0408\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0394\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1783 - accuracy: 0.0410\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0419\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0449\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0412\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0388\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1782 - accuracy: 0.0393\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0421\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1779 - accuracy: 0.0425\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0428\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0411\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0437\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1779 - accuracy: 0.0431\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0362\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1784 - accuracy: 0.0357\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0418\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1779 - accuracy: 0.0419\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1785 - accuracy: 0.0401\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0401\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0442\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0390\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1780 - accuracy: 0.0378\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0433\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0418\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0389\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0409\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0410\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0419\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0393\n",
      "113/113 [==============================] - 3s 24ms/step - loss: 3.1784 - accuracy: 0.0392\n",
      "accuracy for model: 0.03916666656732559\n",
      "experiment 3 done\n",
      "-----------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1788 - accuracy: 0.0414\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1784 - accuracy: 0.0375\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0407\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1781 - accuracy: 0.0398\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1782 - accuracy: 0.0400\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1782 - accuracy: 0.0420\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0395\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1782 - accuracy: 0.0401\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0424\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0364\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0396\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0380\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1782 - accuracy: 0.0377\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0402\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0414\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1782 - accuracy: 0.0428\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0405\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1781 - accuracy: 0.0382\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1782 - accuracy: 0.0423\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 28s 62ms/step - loss: 3.1781 - accuracy: 0.0417\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 27s 61ms/step - loss: 3.1780 - accuracy: 0.0407\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0438\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1780 - accuracy: 0.0395\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0434\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0401\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1782 - accuracy: 0.0404\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0405\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1780 - accuracy: 0.0416\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1782 - accuracy: 0.0428\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1781 - accuracy: 0.0416\n",
      "113/113 [==============================] - 3s 24ms/step - loss: 3.1784 - accuracy: 0.0389\n",
      "accuracy for model: 0.03888889029622078\n",
      "experiment 4 done\n",
      "-----------------\n",
      "Epoch 1/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1783 - accuracy: 0.0412\n",
      "Epoch 2/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1784 - accuracy: 0.0391\n",
      "Epoch 3/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0437\n",
      "Epoch 4/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1784 - accuracy: 0.0384\n",
      "Epoch 5/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0405\n",
      "Epoch 6/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0380\n",
      "Epoch 7/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1779 - accuracy: 0.0451\n",
      "Epoch 8/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1783 - accuracy: 0.0409\n",
      "Epoch 9/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0423\n",
      "Epoch 10/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0402\n",
      "Epoch 11/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0424\n",
      "Epoch 12/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0412\n",
      "Epoch 13/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0386\n",
      "Epoch 14/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0460\n",
      "Epoch 15/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0414\n",
      "Epoch 16/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0416\n",
      "Epoch 17/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1781 - accuracy: 0.0432\n",
      "Epoch 18/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0430\n",
      "Epoch 19/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1783 - accuracy: 0.0361\n",
      "Epoch 20/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1781 - accuracy: 0.0434\n",
      "Epoch 21/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1780 - accuracy: 0.0383\n",
      "Epoch 22/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0384\n",
      "Epoch 23/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1782 - accuracy: 0.0409\n",
      "Epoch 24/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1780 - accuracy: 0.0434\n",
      "Epoch 25/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1783 - accuracy: 0.0400\n",
      "Epoch 26/30\n",
      "450/450 [==============================] - 29s 63ms/step - loss: 3.1782 - accuracy: 0.0386\n",
      "Epoch 27/30\n",
      "450/450 [==============================] - 28s 63ms/step - loss: 3.1782 - accuracy: 0.0395\n",
      "Epoch 28/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1781 - accuracy: 0.0425\n",
      "Epoch 29/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1781 - accuracy: 0.0402\n",
      "Epoch 30/30\n",
      "450/450 [==============================] - 29s 64ms/step - loss: 3.1781 - accuracy: 0.0407\n",
      "113/113 [==============================] - 3s 24ms/step - loss: 3.1784 - accuracy: 0.0389\n",
      "accuracy for model: 0.03888889029622078\n",
      "experiment 5 done\n",
      "-----------------\n",
      "average accuracy: 0.03905555605888367\n"
     ]
    }
   ],
   "source": [
    "#Approach 2, multiclass classification\n",
    "\n",
    "#create classes \n",
    "#start with 24 classes, because of buckets of half an hour\n",
    "classes = [i for i in range(24)]\n",
    "\n",
    "y_class_train = np.zeros(len(y_train))\n",
    "y_class_test = np.zeros(len(y_test))\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    temp_class = y_train[i][0] *2\n",
    "    #if the minutes half past the half\n",
    "    if y_train[i][1] >= 30: temp_class += 1\n",
    "    y_class_train[i] = temp_class\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    temp_class = y_test[i][0] *2\n",
    "    #if the minutes half past the half\n",
    "    if y_test[i][1] >= 30: temp_class += 1\n",
    "    y_class_test[i] = temp_class\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_class_train = keras.utils.to_categorical(y_class_train, len(classes))\n",
    "y_class_test = keras.utils.to_categorical(y_class_test, len(classes))\n",
    "\n",
    "histories = [ ]\n",
    "accuracies = [ ]\n",
    "\n",
    "experiments = 5\n",
    "for i in range(experiments):\n",
    "    DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        DefaultConv2D(filters=64, kernel_size=7, input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        DefaultConv2D(filters=128),\n",
    "        DefaultConv2D(filters=128),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        DefaultConv2D(filters=256),\n",
    "        DefaultConv2D(filters=256),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(units=64, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(units=len(classes), activation='softmax'),\n",
    "        ])\n",
    "    \n",
    "\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer='sgd',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_class_train,\n",
    "            epochs=30)\n",
    "\n",
    "    #print(model.metrics_names)\n",
    "    #print(model.evaluate(x_test,y_class_test))\n",
    "    \n",
    "    temp = model.evaluate(x_test,y_class_test)\n",
    "    accuracies.append(temp[1])\n",
    "    print(\"accuracy for model: \"  + str(temp[1]))\n",
    "    print(\"experiment \" + str(i+1) + \" done\")\n",
    "    print(\"-----------------\")\n",
    "\n",
    "\n",
    "#pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(loc=\"upper left\")\n",
    "#plt.title('Experiment results for multi class approach')\n",
    "#plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1) \n",
    "#plt.show()\n",
    "\n",
    "print(\"average accuracy: \" + str(np.mean(accuracies)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "259/450 [================>.............] - ETA: 5s - loss: 4.1945e-06 - dense_123_loss: 6.5922e-07 - dense_124_loss: 3.5353e-06 - dense_123_accuracy: 0.0790 - dense_123_mean_squared_error: 42.2744 - dense_124_accuracy: 0.0170 - dense_124_mean_squared_error: 1173.8968"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19160/4203322054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     history = model.fit(x_train, [y_hours_train, y_minutes_train],\n\u001b[1;32m---> 67\u001b[1;33m             epochs=30)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m#pd.DataFrame(history.history).plot(figsize=(8, 5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDL\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# approach 3, Multihead models\n",
    "y_hours_train, y_minutes_train = np.split(y_train, 2, 1)\n",
    "y_hours_test, y_minutes_test = np.split(y_test, 2, 1)\n",
    "\n",
    "\n",
    "\n",
    "#print(y_hours[i][0])\n",
    "#y_minutes_train[i][0] -> this gives an integer\n",
    "\n",
    "#common sense error for the multihead\n",
    "#max_difference is the maximal difference between two time labels, which is 6 hours, thus 6*60=360 minutes\n",
    "#max_time is the maximal time in numbers which is 12*60=720, needed to calculate the absolute difference from 12:00 (00:00)\n",
    "def cse_multi(hour1, minutes1, hour2, minutes2, max_difference=360, max_time=720):\n",
    "    #time in the form of minutes, rounded\n",
    "    time1 = hour1 * 60 + minutes1\n",
    "    time2 = hour2 * 60 + minutes2\n",
    "    if time2 > time1: difference = time2 -time1\n",
    "    else: difference = time1 - time2\n",
    "\n",
    "    if difference > max_difference:\n",
    "        difference = max_time - difference\n",
    "    \n",
    "    return difference\n",
    "\n",
    "\n",
    "def calculate_cse(y_true_hours, y_true_minutes, y_pred_hours, y_pred_minutes):\n",
    "    error_list = [ ]\n",
    "    max_difference = 360\n",
    "    for i in range(len(y_true_hours)):\n",
    "        difference = cse_multi(y_true_hours[i][0], y_true_minutes[i][0], y_pred_hours[i][0], y_pred_minutes[i][0])\n",
    "        error_list.append(difference)\n",
    "    return error_list, np.mean(error_list)\n",
    "\n",
    "losses1 = [ ]\n",
    "accuracies1 = [ ]\n",
    "mses1 = [ ]\n",
    "losses2 = [ ]\n",
    "accuracies2 = [ ]\n",
    "mses2 = [ ]\n",
    "cses = [ ]\n",
    "\n",
    "experiments = 5\n",
    "\n",
    "for i in range(experiments):\n",
    "#input = keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)\n",
    "    input = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    hidden1 = keras.layers.Conv2D(64, (3, 3), activation='relu')(input)\n",
    "    hidden2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(hidden1)\n",
    "    hidden3 = keras.layers.Dropout(0.25)(hidden2)\n",
    "    hidden4 = keras.layers.Flatten()(hidden3)\n",
    "    hidden5 = keras.layers.Dense(128, activation='relu')(hidden4)\n",
    "    hidden6 = keras.layers.Dropout(0.5)(hidden5)\n",
    "\n",
    "    output1 = keras.layers.Dense(1)(hidden6)\n",
    "    output2 = keras.layers.Dense(1)(hidden6)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input], outputs=[output1, output2])\n",
    "\n",
    "\n",
    "    #each output needs own loss function \n",
    "    model.compile(loss=[keras.losses.categorical_crossentropy,keras.losses.categorical_crossentropy,],\n",
    "                optimizer='sgd',\n",
    "                metrics=['accuracy', 'mean_squared_error'])\n",
    "\n",
    "    history = model.fit(x_train, [y_hours_train, y_minutes_train],\n",
    "            epochs=30)\n",
    "\n",
    "    #pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    #plt.grid(True)\n",
    "    #plt.gca().set_ylim(0, 1) \n",
    "    #plt.show()\n",
    "\n",
    "    #print(model.metrics_names)\n",
    "    temp = model.evaluate(x_test,[y_hours_test,y_minutes_test])\n",
    "    losses1.append(temp[1])\n",
    "    accuracies1.append(temp[3])\n",
    "    mses1.append(temp[4])\n",
    "    losses2.append(temp[2])\n",
    "    accuracies2.append(temp[5])\n",
    "    mses2.append(temp[6])\n",
    "\n",
    "    y_hours_pred, y_minutes_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "    error_list, error = calculate_cse(y_hours_test, y_minutes_test, y_hours_pred, y_minutes_pred)\n",
    "    print(\"common sense error: \" + str(error))\n",
    "    cses.append(error)\n",
    "\n",
    "    print(\"experiment :\" + str(i+1) + \" done\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "print(\"average CSE: \" + str(np.mean(cses)))\n",
    "print(\"average loss1: \" + str(np.mean(losses1)))\n",
    "print(\"average accurary 1: \" + str(np.mean(accuracies1)))\n",
    "print(\"average MSE 1: \" + str(np.mean(mses1)))\n",
    "print(\"average loss 2: \" + str(np.mean(losses2)))\n",
    "print(\"average accurary 2: \" + str(np.mean(accuracies2)))\n",
    "print(\"average MSE 2: \" + str(np.mean(mses2)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff5fe94655e3d5310330fd753d5059a21acd88ad4a4e27edf074c52986bc0712"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('IDL': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

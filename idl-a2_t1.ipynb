{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define initial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "epochs = 30\n",
    "validation_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_valid(dataset, verbose=False, rand_permute=False):\n",
    "  (X_train, y_train), (X_test, y_test) = dataset.load_data()\n",
    "  if rand_permute:\n",
    "    if verbose:\n",
    "      print(\"Creating random permutation\")\n",
    "    # I have checked the permuted and non permuted datasets with the same\n",
    "    # randomstate and the columns are correctly permuted, i.e. the values\n",
    "    # from the rows in the columns match\n",
    "    X = np.concatenate((X_train.reshape(X_train.shape[0], 784), X_test.reshape(X_test.shape[0], 784)))\n",
    "    X = np.random.permutation(X.T)\n",
    "    X_train = X.T[:X_train.shape[0]]\n",
    "    X_test = X.T[-X_test.shape[0]:]\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28,28)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28,28)\n",
    "\n",
    "  X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_size)#, random_state=1)\n",
    "\n",
    "  X_train = X_train.reshape(int(60000 * (1.0 - validation_size)), 28, 28, 1)\n",
    "  X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "  X_valid = X_valid.reshape(int(60000 * validation_size), 28, 28, 1)\n",
    "\n",
    "  X_train = X_train.astype('float32')\n",
    "  X_test = X_test.astype('float32')\n",
    "  X_valid = X_valid.astype('float32')\n",
    "\n",
    "  X_train /= 255\n",
    "  X_test /= 255\n",
    "  X_valid /= 255\n",
    "\n",
    "  # convert class vectors to binary class matrices\n",
    "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "  y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "  \n",
    "  if verbose:\n",
    "    \"\"\"\n",
    "    #Picture of the first training instance\n",
    "    img = X_train[0].reshape([28, 28]);\n",
    "    plt.gray()\n",
    "    plt.imshow(img)\n",
    "    \"\"\"\n",
    "    print(X_train.shape, 'train samples')\n",
    "    print(X_test.shape, 'test samples')\n",
    "    print(X_valid.shape, 'validation samples')\n",
    "\n",
    "    print(y_train.shape, 'train labels')\n",
    "    print(y_test.shape, 'test labels')\n",
    "    print(y_valid.shape, 'validation labels')\n",
    "\n",
    "  return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, X_train, y_train, X_valid, y_valid, verbose):\n",
    "  model.compile(loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"])\n",
    "  #track epoch loss history\n",
    "  if not verbose:\n",
    "    history = model.fit(X_train, y_train, epochs=epochs,verbose = 0,\n",
    "                        validation_data=(X_valid, y_valid))\n",
    "  else:\n",
    "    history = model.fit(X_train, y_train, epochs=epochs,\n",
    "                        validation_data=(X_valid, y_valid))\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltHistory(history):\n",
    "  pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "  plt.grid(True)\n",
    "  plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute experiments for a given model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExperiment(model, dataset, verbose=False, rand_permute=False, plot_hist=True):\n",
    "  X_train, y_train, X_test, y_test, X_valid, y_valid = split_train_test_valid(dataset, verbose, rand_permute)\n",
    "  print(\"--- Training Model ...\")\n",
    "  history = trainModel(model, X_train, y_train, X_valid, y_valid, verbose)\n",
    "  if plot_hist == True:\n",
    "    print(\"--- History:\")\n",
    "    pltHistory(history)\n",
    "    print(\"--- Evaluation:\")\n",
    "  return model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = keras.models.Sequential([\n",
    "  keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "  keras.layers.Dense(300, activation=\"relu\"),\n",
    "  keras.layers.Dense(100, activation=\"relu\"),\n",
    "  keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Splitting Data ...\n",
      "Creating random permutation\n",
      "(54000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(6000, 28, 28, 1) validation samples\n",
      "(54000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "(6000, 10) validation labels\n",
      "--- Training Model ...\n",
      "Epoch 1/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 1.0210 - accuracy: 0.7361 - val_loss: 0.3113 - val_accuracy: 0.9103\n",
      "Epoch 2/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3038 - accuracy: 0.9131 - val_loss: 0.2506 - val_accuracy: 0.9260\n",
      "Epoch 3/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2441 - accuracy: 0.9315 - val_loss: 0.2078 - val_accuracy: 0.9412\n",
      "Epoch 4/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2020 - accuracy: 0.9431 - val_loss: 0.1834 - val_accuracy: 0.9478\n",
      "Epoch 5/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1764 - accuracy: 0.9494 - val_loss: 0.1616 - val_accuracy: 0.9532\n",
      "Epoch 6/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1634 - accuracy: 0.9522 - val_loss: 0.1506 - val_accuracy: 0.9552\n",
      "Epoch 7/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1413 - accuracy: 0.9597 - val_loss: 0.1375 - val_accuracy: 0.9585\n",
      "Epoch 8/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1274 - accuracy: 0.9632 - val_loss: 0.1308 - val_accuracy: 0.9613\n",
      "Epoch 9/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1174 - accuracy: 0.9666 - val_loss: 0.1177 - val_accuracy: 0.9663\n",
      "Epoch 10/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1030 - accuracy: 0.9710 - val_loss: 0.1117 - val_accuracy: 0.9675\n",
      "Epoch 11/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0962 - accuracy: 0.9737 - val_loss: 0.1079 - val_accuracy: 0.9680\n",
      "Epoch 12/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0895 - accuracy: 0.9749 - val_loss: 0.1010 - val_accuracy: 0.9702\n",
      "Epoch 13/30\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0853 - accuracy: 0.9760 - val_loss: 0.0951 - val_accuracy: 0.9718\n",
      "Epoch 14/30\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0778 - accuracy: 0.9782 - val_loss: 0.0919 - val_accuracy: 0.9708\n",
      "Epoch 15/30\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0714 - accuracy: 0.9807 - val_loss: 0.0875 - val_accuracy: 0.9733\n",
      "Epoch 16/30\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0708 - accuracy: 0.9815 - val_loss: 0.0856 - val_accuracy: 0.9742\n",
      "Epoch 17/30\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0637 - accuracy: 0.9829 - val_loss: 0.0830 - val_accuracy: 0.9752\n",
      "Epoch 18/30\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0580 - accuracy: 0.9845 - val_loss: 0.0812 - val_accuracy: 0.9752\n",
      "Epoch 19/30\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0547 - accuracy: 0.9857 - val_loss: 0.0780 - val_accuracy: 0.9753\n",
      "Epoch 20/30\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0508 - accuracy: 0.9864 - val_loss: 0.0775 - val_accuracy: 0.9758\n",
      "Epoch 21/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0469 - accuracy: 0.9881 - val_loss: 0.0774 - val_accuracy: 0.9765\n",
      "Epoch 22/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0474 - accuracy: 0.9877 - val_loss: 0.0810 - val_accuracy: 0.9767\n",
      "Epoch 23/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0462 - accuracy: 0.9880 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
      "Epoch 24/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0407 - accuracy: 0.9900 - val_loss: 0.0721 - val_accuracy: 0.9777\n",
      "Epoch 25/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0384 - accuracy: 0.9909 - val_loss: 0.0693 - val_accuracy: 0.9790\n",
      "Epoch 26/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0349 - accuracy: 0.9914 - val_loss: 0.0690 - val_accuracy: 0.9792\n",
      "Epoch 27/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.0700 - val_accuracy: 0.9792\n",
      "Epoch 28/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0318 - accuracy: 0.9933 - val_loss: 0.0701 - val_accuracy: 0.9793\n",
      "Epoch 29/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0275 - accuracy: 0.9941 - val_loss: 0.0674 - val_accuracy: 0.9803\n",
      "Epoch 30/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0280 - accuracy: 0.9936 - val_loss: 0.0678 - val_accuracy: 0.9780\n",
      "--- History:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation:\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07324954867362976, 0.977400004863739]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doExperiment(mlp_model, mnist, verbose=True, rand_permute=True, plot_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fashion_mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Splitting Data ...\n",
      "Creating random permutation\n",
      "(54000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(6000, 28, 28, 1) validation samples\n",
      "(54000, 10) train labels\n",
      "(10000, 10) test labels\n",
      "(6000, 10) validation labels\n",
      "--- Training Model ...\n",
      "Epoch 1/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.8225 - accuracy: 0.7476 - val_loss: 0.4472 - val_accuracy: 0.8483\n",
      "Epoch 2/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.4332 - accuracy: 0.8443 - val_loss: 0.4264 - val_accuracy: 0.8472\n",
      "Epoch 3/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3788 - accuracy: 0.8664 - val_loss: 0.4101 - val_accuracy: 0.8542\n",
      "Epoch 4/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3549 - accuracy: 0.8743 - val_loss: 0.3647 - val_accuracy: 0.8700\n",
      "Epoch 5/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3382 - accuracy: 0.8797 - val_loss: 0.3691 - val_accuracy: 0.8632\n",
      "Epoch 6/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3182 - accuracy: 0.8859 - val_loss: 0.3993 - val_accuracy: 0.8538\n",
      "Epoch 7/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3085 - accuracy: 0.8882 - val_loss: 0.3383 - val_accuracy: 0.8778\n",
      "Epoch 8/30\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3097 - accuracy: 0.8886 - val_loss: 0.3347 - val_accuracy: 0.8808\n",
      "Epoch 9/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2938 - accuracy: 0.8934 - val_loss: 0.3488 - val_accuracy: 0.8770\n",
      "Epoch 10/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2895 - accuracy: 0.8946 - val_loss: 0.3286 - val_accuracy: 0.8835\n",
      "Epoch 11/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2763 - accuracy: 0.8996 - val_loss: 0.3246 - val_accuracy: 0.8830\n",
      "Epoch 12/30\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2706 - accuracy: 0.9025 - val_loss: 0.3099 - val_accuracy: 0.8893\n",
      "Epoch 13/30\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2568 - accuracy: 0.9072 - val_loss: 0.3752 - val_accuracy: 0.8600\n",
      "Epoch 14/30\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2599 - accuracy: 0.9058 - val_loss: 0.3361 - val_accuracy: 0.8767\n",
      "Epoch 15/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2506 - accuracy: 0.9111 - val_loss: 0.3066 - val_accuracy: 0.8893\n",
      "Epoch 16/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2440 - accuracy: 0.9121 - val_loss: 0.3075 - val_accuracy: 0.8900\n",
      "Epoch 17/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2372 - accuracy: 0.9138 - val_loss: 0.3087 - val_accuracy: 0.8893\n",
      "Epoch 18/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2334 - accuracy: 0.9163 - val_loss: 0.3129 - val_accuracy: 0.8857\n",
      "Epoch 19/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2279 - accuracy: 0.9177 - val_loss: 0.3124 - val_accuracy: 0.8855\n",
      "Epoch 20/30\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2197 - accuracy: 0.9209 - val_loss: 0.3157 - val_accuracy: 0.8843\n",
      "Epoch 21/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2188 - accuracy: 0.9207 - val_loss: 0.3064 - val_accuracy: 0.8898\n",
      "Epoch 22/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2100 - accuracy: 0.9236 - val_loss: 0.2883 - val_accuracy: 0.8932\n",
      "Epoch 23/30\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2111 - accuracy: 0.9242 - val_loss: 0.3142 - val_accuracy: 0.8873\n",
      "Epoch 24/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2046 - accuracy: 0.9274 - val_loss: 0.3085 - val_accuracy: 0.8880\n",
      "Epoch 25/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2034 - accuracy: 0.9268 - val_loss: 0.3033 - val_accuracy: 0.8920\n",
      "Epoch 26/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2003 - accuracy: 0.9266 - val_loss: 0.3071 - val_accuracy: 0.8907\n",
      "Epoch 27/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1919 - accuracy: 0.9308 - val_loss: 0.2941 - val_accuracy: 0.8912\n",
      "Epoch 28/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1860 - accuracy: 0.9340 - val_loss: 0.2947 - val_accuracy: 0.8910\n",
      "Epoch 29/30\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1870 - accuracy: 0.9331 - val_loss: 0.3420 - val_accuracy: 0.8792\n",
      "Epoch 30/30\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1841 - accuracy: 0.9342 - val_loss: 0.3263 - val_accuracy: 0.8837\n",
      "--- History:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation:\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36003437638282776, 0.8755999803543091]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doExperiment(mlp_model, fashion_mnist, verbose=True, rand_permute=True, plot_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP settings experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 827us/step - loss: 0.4582 - accuracy: 0.8380\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8658\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 901us/step - loss: 0.3553 - accuracy: 0.8740\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8772\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8756\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8743\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8745\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8756\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8746\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 876us/step - loss: 0.3717 - accuracy: 0.8670\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 954us/step - loss: 0.3590 - accuracy: 0.8711\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 939us/step - loss: 0.3855 - accuracy: 0.8611\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 939us/step - loss: 0.3420 - accuracy: 0.8760\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 945us/step - loss: 0.3560 - accuracy: 0.8696\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 962us/step - loss: 0.3343 - accuracy: 0.8805\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 974us/step - loss: 0.3364 - accuracy: 0.8790\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8770\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8788\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 908us/step - loss: 0.3563 - accuracy: 0.8720\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 984us/step - loss: 0.3567 - accuracy: 0.8744\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8818\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8772\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8780\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8716\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8780\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8798\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8701\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8801\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8818\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8801\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8763\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8792\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8759\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8823\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8764\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8823\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8814\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8804\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8829\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8843\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8809\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8794\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8771\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8788\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8839\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8762\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8785\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8785\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8867\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8826\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8822\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8763\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8874\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8830\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8802\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8756\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8833\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8873\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3764 - accuracy: 0.8655\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8819\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8847\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8864\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8790\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8827\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8792\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.8734\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8854\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8875\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8765\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8759\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8832\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8753\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8872\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8788\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3687 - accuracy: 0.8654\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.8871\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3170 - accuracy: 0.8878\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 963us/step - loss: 0.3619 - accuracy: 0.8722\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 997us/step - loss: 0.3433 - accuracy: 0.8763\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8751\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8738\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8801\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8717\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8776\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8724\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8547\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8721\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8840\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8789\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8693\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8793\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8810\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8735\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8810\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8727\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8698\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8761\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8789\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8688\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8849\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8792\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8758\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8763\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8830\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8707\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8846\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8824\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8804\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8804\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8754\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8692\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8809\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8765\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8783\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8780\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8790\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8731\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8824\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3848 - accuracy: 0.8629\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8797\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8724\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8807\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8777\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8837\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8827\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8812\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8697\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8757\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8750\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3705 - accuracy: 0.8721\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8774\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8777\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8829\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8752\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8816\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3686 - accuracy: 0.8648\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8853\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8842\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8851\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8784\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8801\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8819\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8735\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8795\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8857\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8802\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8686\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8859\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8716\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8705\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8667\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8797\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8826\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8749\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.8747\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8766\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8720\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8810\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8738\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8753\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8760\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8802\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8762\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8770\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8773\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8720\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8766\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8826\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8749\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8788\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8837\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8764\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8792\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8759\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8777\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8866\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8851\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3757 - accuracy: 0.8700\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8707\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8832\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8823\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8856\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8827\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8841\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8875\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8843\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8836\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8850\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8780\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8787\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8809\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8778\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8805\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8869\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8877\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8836\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.8870\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8786\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8794\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8779\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8863\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8833\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8741\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8770\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3177 - accuracy: 0.8892\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8840\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8580\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8753\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8880\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8528\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8857\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8714\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8793\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8721\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8857\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8808\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8821\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8828\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8875\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8858\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8816\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8842\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8874\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8805\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8835\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8773\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8761\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8890\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8815\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8838\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3219 - accuracy: 0.8890\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8875\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8826\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8824\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8742\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8791\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8831\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8770\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8792\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8850\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8853\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8805\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8740\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8798\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8891\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8770\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8861\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8757\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8799\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8779\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8778\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8781\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8716\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8870\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8831\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8850\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8801\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8790\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8815\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8856\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8802\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8828\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8808\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8784\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3825 - accuracy: 0.8692\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8865\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8746\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8688\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8803\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8821\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8865\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8817\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.8921\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3372 - accuracy: 0.8804\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8821\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8864\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3664 - accuracy: 0.8755\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8787\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8861\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8817\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8807\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8647\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8787\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3698 - accuracy: 0.8716\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8806\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8787\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8785\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8810\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3195 - accuracy: 0.8877\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8837\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8793\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8771\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8861\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8801\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8846\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8848\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8892\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3905 - accuracy: 0.8630\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3655 - accuracy: 0.8675\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8864\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8852\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8878\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8687\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8874\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8850\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8776\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8820\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3903 - accuracy: 0.8684\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8842\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8749\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8750\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.8759\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8813\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8675\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8826\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8802\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8764\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3236 - accuracy: 0.8857\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8829\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8807\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8843\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8793\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8782\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8822\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8693\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8714\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8682\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8868\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8781\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8864\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8860\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8754\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8717\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8812\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8788\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8876\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8818\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8791\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8859\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8808\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8879\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8848\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8802\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8823\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8934\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3133 - accuracy: 0.8896\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8854\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3469 - accuracy: 0.8790\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8788\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8871\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8881\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8812\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3803 - accuracy: 0.8749\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8863\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8800\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8890\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8774\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8923\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8872\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8867\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8785\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8818\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8847\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8720\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3205 - accuracy: 0.8895\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8791\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8834\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8843\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8579\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8832\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3200 - accuracy: 0.8880\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8822\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8832\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8862\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8841\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8729\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8784\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8883\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8783\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3570 - accuracy: 0.8761\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8868\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8841\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8872\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8780\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8804\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8900\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8812\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8814\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8883\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8832\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3961 - accuracy: 0.8594\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.8913\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8710\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8712\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8791\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8860\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8861\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8844\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3245 - accuracy: 0.8835\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8815\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8814\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8828\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8874\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8825\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8810\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8738\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8624\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8809\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8830\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8812\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8902\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8731\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8874\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8786\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8834\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8796\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8832\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8833\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8842\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8848\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8843\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8787\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8900\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8807\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8821\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8913\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8885\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8856\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8895\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8887\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8871\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8817\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8861\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8847\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8883\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8820\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8877\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8902\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3155 - accuracy: 0.8892\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8887\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8773\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3411 - accuracy: 0.8786\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8806\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3373 - accuracy: 0.8818\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8592\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8762\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3314 - accuracy: 0.8870\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.8455\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8840\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3694 - accuracy: 0.8706\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8846\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3164 - accuracy: 0.8898\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3893 - accuracy: 0.8628\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8777\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8824\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8853\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8900\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8870\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8919\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8837\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8803\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8854\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3542 - accuracy: 0.8735\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8853\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8893\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3194 - accuracy: 0.8899\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3725 - accuracy: 0.8766\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3726 - accuracy: 0.8722\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8854\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.8898\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8753\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8879\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8799\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8777\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8882\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8882\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8845\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8824\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8828\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8783\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8765\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3806 - accuracy: 0.8696\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3855 - accuracy: 0.8711\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8846\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8814\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4254 - accuracy: 0.8561\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8841\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.8740\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8849\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8721\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8820\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8887\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8767\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8901\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.8837\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8859\n",
      "--- Splitting Data ...\n",
      "--- Training Model ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ba1d71e317b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m#print(mlp_model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_hist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mmlp_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;31m#print(f'layer one {l1} layer two {l2} layer three {l3}  with a score of loss {score[0]} and accuracy {score[1]}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-07ff3d0c00be>\u001b[0m in \u001b[0;36mdoExperiment\u001b[0;34m(model, dataset, verbose, rand_permute, plot_hist)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_permute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Training Model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mplot_hist\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- History:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4c209a36536a>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(model, X_train, y_train, X_valid, y_valid, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#track epoch loss history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     history = model.fit(X_train, y_train, epochs=epochs,verbose = 0,\n\u001b[0m\u001b[1;32m      8\u001b[0m                         validation_data=(X_valid, y_valid))\n\u001b[1;32m      9\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_scores = {}\n",
    "for l1 in range(0,801, 100): \n",
    "  for l2 in range(0,801,100):\n",
    "    for l3 in range(0,801, 100):\n",
    "      mlp_model = keras.models.Sequential([keras.layers.Flatten(input_shape=[28, 28, 1])])\n",
    "      if not l1 == 0: \n",
    "        mlp_model.add(keras.layers.Dense(l1, activation=\"relu\"))\n",
    "      if not l2 == 0: \n",
    "        mlp_model.add(keras.layers.Dense(l2, activation=\"relu\"))\n",
    "      if not l3 == 0: \n",
    "        mlp_model.add(keras.layers.Dense(l3, activation=\"relu\"))\n",
    "      mlp_model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "      #print(mlp_model.summary())\n",
    "      score = doExperiment(mlp_model, fashion_mnist, verbose=False, plot_hist=False)\n",
    "      mlp_scores[l1,l2,l3] = score\n",
    "      #print(f'layer one {l1} layer two {l2} layer three {l3}  with a score of loss {score[0]} and accuracy {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8788380949270158\n"
     ]
    }
   ],
   "source": [
    "# average Performance\n",
    "avg = 0\n",
    "c=0\n",
    "for k,v in mlp_scores.items():\n",
    "  if not k[0] == 0 and not k[1] == 0 and k[2] == 0:\n",
    "    c+=1\n",
    "    avg += v[1]\n",
    "print(avg/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HeatMap Creation\n",
    "mlp_scores2d = pd.DataFrame(columns = ['Layer One', 'Layer Two', 'Accuracy'])\n",
    "for k,v in mlp_scores.items():\n",
    "  if k[2]== 0 :\n",
    "    mlp_scores2d = mlp_scores2d.append({'Layer One': k[0], 'Layer Two':k[1], 'Accuracy':v[1]}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "cnn_model = keras.models.Sequential([\n",
    "DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "keras.layers.MaxPooling2D(pool_size=2),\n",
    "DefaultConv2D(filters=128),\n",
    "DefaultConv2D(filters=128),\n",
    "keras.layers.MaxPooling2D(pool_size=2),\n",
    "DefaultConv2D(filters=256),\n",
    "DefaultConv2D(filters=256),\n",
    "keras.layers.MaxPooling2D(pool_size=2),\n",
    "keras.layers.Flatten(),\n",
    "keras.layers.Dense(units=128, activation='relu'),\n",
    "keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(units=64, activation='relu'),\n",
    "keras.layers.Dropout(0.5),\n",
    "keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doExperiment(cnn_model, mnist, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doExperiment(cnn_model, fmnist, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_scores = {}\n",
    "\n",
    "for kernal_size in [0,1,2,3]:\n",
    "  for max_pooling_size in [0,1,2,3]:\n",
    "    DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3+ kernal_size, activation='relu', padding=\"SAME\")\n",
    "    if not max_pooling_size == 0:\n",
    "      cnn_model = keras.models.Sequential([\n",
    "          DefaultConv2D(filters=64, kernel_size=7+kernal_size, input_shape=[28, 28, 1]),\n",
    "          \n",
    "          keras.layers.MaxPooling2D(pool_size=max_pooling_size),\n",
    "          DefaultConv2D(filters=128),\n",
    "          DefaultConv2D(filters=128),\n",
    "          keras.layers.MaxPooling2D(pool_size=max_pooling_size),\n",
    "          DefaultConv2D(filters=256),\n",
    "          DefaultConv2D(filters=256),\n",
    "          keras.layers.MaxPooling2D(pool_size=max_pooling_size),\n",
    "          keras.layers.Flatten(),\n",
    "          keras.layers.Dense(units=128, activation='relu'),\n",
    "          keras.layers.Dropout(0.5),\n",
    "          keras.layers.Dense(units=64, activation='relu'),\n",
    "          keras.layers.Dropout(0.5),\n",
    "          keras.layers.Dense(units=10, activation='softmax'),\n",
    "          ])\n",
    "    else:\n",
    "      cnn_model = keras.models.Sequential([\n",
    "          DefaultConv2D(filters=64, kernel_size=7+kernal_size, input_shape=[28, 28, 1]),\n",
    "          DefaultConv2D(filters=128),\n",
    "          DefaultConv2D(filters=128),\n",
    "          DefaultConv2D(filters=256),\n",
    "          DefaultConv2D(filters=256),\n",
    "          keras.layers.Flatten(),\n",
    "          keras.layers.Dense(units=128, activation='relu'),\n",
    "          keras.layers.Dropout(0.5),\n",
    "          keras.layers.Dense(units=64, activation='relu'),\n",
    "          keras.layers.Dropout(0.5),\n",
    "          keras.layers.Dense(units=10, activation='softmax'),\n",
    "          ])\n",
    "    score = doExperiment(cnn_model, fashion_mnist, verbose=False)\n",
    "    cnn_scores[max_pooling_size,kernal_size] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_scores2d = pd.DataFrame(columns = ['Max Pooling Size', 'Kernel Size', 'Accuracy'])\n",
    "for k,v in cnn_scores.items():\n",
    "    cnn_scores2d = cnn_scores2d.append({'Max Pooling Size': k[0], 'Kernel Size':k[1], 'Accuracy':v[1]}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmapdf = cnn_scores2d.set_index(['Max Pooling Size','Kernel Size'])\n",
    "heatmapdf = heatmapdf.unstack(level=0)\n",
    "ax = sns.heatmap(heatmapdf, annot=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
